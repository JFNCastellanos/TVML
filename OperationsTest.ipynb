{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0cd4fba-0d61-4995-ae3d-b127608080c5",
   "metadata": {},
   "source": [
    "# Testing operations with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa6dfe3-9d75-4267-8b81-923445d3384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import parameters as var #Configuration and coarsening parameters\n",
    "var.init() #initializes parameters\n",
    "import utils as ut #Some utility functions \n",
    "import loss_function as lf #Custom loss function\n",
    "\n",
    "\n",
    "from opendataset import ConfsDataset #class for opening gauge confs\n",
    "from opendataset import read_binary_conf\n",
    "import operators as op #Interpolator and prolongator given a set of test vectors\n",
    "import operators_torch as opt #Same implementations but with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b6560-154e-4f36-b1d3-0d3f089c4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_loss(pred_test_vectors,test_vectors):\n",
    "    loss = 0\n",
    "    for i in range(batch_size):\n",
    "        ops = op.Operators(var.BLOCKS_X,var.BLOCKS_T,pred_test_vectors[i])\n",
    "        for tv in range(var.NV):\n",
    "            #Evaluate \n",
    "            loss += np.linalg.norm( (test_vectors[i,tv] - ops.P_Pdagg(test_vectors[i,tv])) )\n",
    "            #loss = np.linealg.norm(test_vectors - P_Pdagg(test_vectors)) #|| . ||₂ (l2-norm)\n",
    "    return loss\n",
    "\n",
    "def torch_loss(pred, target):\n",
    "    \"\"\"\n",
    "    pred  : Tensor of shape (B, NV, 2, NT, NX)   (complex numbers stored as complex dtype)\n",
    "    target: Tensor of shape (B, NV, 2, NT, NX)   (the “near kernel” vectors)\n",
    "    Returns a scalar loss Tensor (requires_grad=True)\n",
    "    \"\"\"\n",
    "    batch_size = pred.shape[0]\n",
    "    loss = 0.0\n",
    "    for i in range(batch_size):\n",
    "            \n",
    "        ops = opt.Operators(var.BLOCKS_X, var.BLOCKS_T, pred[i])   \n",
    "        for tv in range(var.NV):\n",
    "            corrected = ops.P_Pdagg(target[i, tv])               \n",
    "            diff = target[i, tv] - corrected\n",
    "            loss = loss + torch.linalg.norm(diff)   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd325be-7f4e-4499-b410-edceb4ad4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_loss_ind(pred_test_vectors,test_vectors):\n",
    "    loss = 0.0\n",
    "    ops = op.Operators(var.BLOCKS_X,var.BLOCKS_T,pred_test_vectors)\n",
    "    if test_vectors.shape[0] == var.NV:\n",
    "        for tv in range(var.NV):\n",
    "            #Evaluate \n",
    "            loss += np.linalg.norm( (test_vectors[tv] - ops.P_Pdagg(test_vectors[tv])) )\n",
    "            #loss = np.linealg.norm(test_vectors - P_Pdagg(test_vectors)) #|| . ||₂ (l2-norm)\n",
    "    else:\n",
    "        loss += np.linalg.norm( (test_vectors - ops.P_Pdagg(test_vectors)) )\n",
    "    return loss\n",
    "\n",
    "def torch_loss_ind(pred, target):\n",
    "    loss = 0.0      \n",
    "    ops = opt.Operators(var.BLOCKS_X, var.BLOCKS_T, pred)\n",
    "    if target.shape[0] == var.NV:\n",
    "        for tv in range(var.NV):\n",
    "            corrected = ops.P_Pdagg(target[tv])               \n",
    "            diff = target[tv] - corrected\n",
    "            loss = loss + torch.linalg.norm(diff)\n",
    "    else:\n",
    "        loss += torch.linalg.norm( (target - ops.P_Pdagg(target)) )  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f58947-a3e0-42fa-ac94-4f6a828a92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the configurations and the near-kernel test vectors\n",
    "\"\"\"\n",
    "workers = 4\n",
    "batch_size = 300\n",
    "dataset = ConfsDataset()\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                shuffle=False, num_workers=workers)\n",
    "\n",
    "#----returns a tensor of size [ [batch_size,4,Nx,Nt], [batch_size,Nv,2,Nx,Nt] ]----#\n",
    "first_batch = next(iter(dataloader)) \n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46485931-e1a1-4faa-b070-3bb8cef94ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For testing torch vs numpy\n",
    "test = first_batch[1][0]\n",
    "\n",
    "print(\"set of test vectors\",type(test))\n",
    "oper = op.Operators(var.BLOCKS_X, var.BLOCKS_T,test)\n",
    "tvecs = oper.getTestVectors()\n",
    "print(\"numpy vectors\",type(tvecs))\n",
    "oper_torch = opt.Operators(var.BLOCKS_X, var.BLOCKS_T,test)\n",
    "tvecs_torch = oper_torch.getTestVectors()\n",
    "print(\"torch vectors\",type(tvecs_torch))\n",
    "print(tvecs.shape,tvecs_torch.shape)\n",
    "print(\"test vectors\",tvecs[0,1,2,2],tvecs_torch[0,1,2,2])\n",
    "\n",
    "v = np.random.rand(2,var.NT,var.NX) + 1j*np.random.rand(2,var.NT,var.NX)\n",
    "vc = np.random.rand(var.NV,2,var.BLOCKS_T,var.BLOCKS_X) + 1j*np.random.rand(var.NV,2,var.BLOCKS_T,var.BLOCKS_X)\n",
    "\n",
    "vtorch = torch.tensor(v)\n",
    "vctorch = torch.tensor(vc)\n",
    "\n",
    "\n",
    "out = oper.P_vc(vc)\n",
    "print(\"Pvc (np)\",out[0,5,0],type(out))\n",
    "outt = oper_torch.P_vc(vctorch)\n",
    "print(\"Pvc (torch)\",outt[0,5,0],type(outt))\n",
    "\n",
    "out = oper.P_Pdagg(v)\n",
    "print(\"PP^+ (np)\",v[0,5,0],out[0,5,0])\n",
    "outvc = oper.Pdagg_P(vc)\n",
    "print(\"P^+P (np)\",vc[0,0,0,0],outvc[0,0,0,0])\n",
    "\n",
    "outt = oper_torch.P_Pdagg(vtorch)\n",
    "print(\"PP^+ (torch)\",vtorch[0,5,0],outt[0,5,0])\n",
    "outvct = oper_torch.Pdagg_P(vctorch)\n",
    "print(\"P^+P (torch)\",vctorch[0,0,0,0],outvct[0,0,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed47d9-f06c-42e8-8664-8e2a139c2caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = np.zeros((var.NV,2,var.NT,var.NX),dtype=complex)\n",
    "#random.seed(0)\n",
    "for tv in range(var.NV):\n",
    "    for nt in range(var.NT):\n",
    "        for nx in range(var.NX):\n",
    "            for s in range(2):\n",
    "                x = random.random()\n",
    "                y = random.random()\n",
    "                z = complex(x, y)\n",
    "                test_vectors[tv,s,nt,nx] = z   #2*(nx*NT + nt) + s + 1 + tv*2*NX*NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3fd38-1883-4965-83b7-edd8cc49a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy_loss_ind(first_batch[1][0].numpy(),first_batch[1][0].numpy()))\n",
    "print(torch_loss_ind(first_batch[1][0],first_batch[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70ccae-5f1d-4f2d-9bde-0e83f2cfc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy_loss_ind(first_batch[1][0].numpy(),test_vectors))\n",
    "print(torch_loss_ind(first_batch[1][0],torch.tensor(test_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ddef4-e82f-46cb-8694-c4df4241d9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = 0.0\n",
    "remTV = 15-var.NV\n",
    "for confID in range(batch_size):\n",
    "    print(\"confID\",confID)\n",
    "    for i in range(remTV):\n",
    "        tvector = np.zeros((2,var.NT,var.NX),dtype=complex)\n",
    "        path = 'confs/near_kernel/b{0}_{1}x{2}/{3}/tvector_{1}x{2}_b{0}0000_m{4}_nconf{5}_tv{6}.tv'.format(\n",
    "        int(var.BETA),var.NX,var.NT,var.M0_FOLDER,var.M0_STRING,confID,14-i)\n",
    "        tvector = read_binary_conf(None,path)\n",
    "        print(\"Test vector \",14-i)\n",
    "        loss += numpy_loss_ind(first_batch[1][confID].numpy(),tvector)\n",
    "        print(\"Numpy\",numpy_loss_ind(first_batch[1][confID].numpy(),tvector))\n",
    "        print(\"PyTorch\",torch_loss_ind(first_batch[1][confID],torch.tensor(tvector)))\n",
    "    print(\"----------------------\")\n",
    "print(\"Final loss on the remainder test vectors\",loss/(batch_size*remTV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa41169-9a3a-49c7-b703-af8d33cdcf2d",
   "metadata": {},
   "source": [
    "Final loss on the remainder test vectors 9.386980374900652 (for 4 test vectors and using the rest to check the loss function)\n",
    "Final loss on the remainder test vectors 2.5979268393039137 (for 14 test vectors and using the rest to check the loss function)\n",
    "\n",
    "This shows that the more smoothed test vectors, the better they capture other near-kernel components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65273607-c0f8-46b7-94ce-a74125184763",
   "metadata": {},
   "source": [
    "Just out of curiosity. What happens if I evaluate the metric just on random vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ca2df-261e-481d-abbe-6c7bf900a6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = 0.0\n",
    "for confID in range(batch_size):\n",
    "    print(\"confID\",confID)\n",
    "    for i in range(var.NV):\n",
    "        tvector = np.random.rand(2,var.NT,var.NX) + 1j*np.random.rand(2,var.NT,var.NX)\n",
    "        print(\"Test vector \",14-i)\n",
    "        loss += numpy_loss_ind(first_batch[1][confID].numpy(),tvector)\n",
    "        print(\"Numpy\",numpy_loss_ind(first_batch[1][confID].numpy(),tvector))\n",
    "        print(\"PyTorch\",torch_loss_ind(first_batch[1][confID],torch.tensor(tvector)))\n",
    "    print(\"----------------------\")\n",
    "print(\"Final loss on the remainder test vectors\",loss/(batch_size*var.NV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a083c08f-bd42-406f-b8e2-58db1382e9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
