{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3404391c-e8ae-4c58-b700-ca8b1e032a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Configuration parameters ***********\n",
      "* Î²=2, Nx=32, Nt=32\n",
      "* Lattice sites=2048\n",
      "* m0=-0.1884\n",
      "* blocks_x=2, blocks_t=2 (for the aggregation)\n",
      "* Nv=20\n",
      "* Number of confs=1000\n",
      "* Confs used for training=900\n",
      "************************************************\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.parallel\n",
    "import random\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import parameters as var #Configuration and coarsening parameters\n",
    "var.init() #initializes parameters\n",
    "import utils as ut #Some utility functions \n",
    "import loss_function as lf #Custom loss function\n",
    "\n",
    "import operators_torch as op #Interpolator and prolongator given a set of test vectors\n",
    "from opendataset import ConfsDataset #class for opening gauge confs\n",
    "import model as mod #import machine learning model\n",
    "\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "\n",
    "#--------Most likely I will need some of these in the future-------#\n",
    "#import torch.optim as optim\n",
    "#import torchvision.transforms as transforms\n",
    "#import torchvision.utils as vutils\n",
    "var.print_parameters()\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if var.NGPU>0\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9b6787-40ee-4e7b-95d1-624b9fa7ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the configurations and the near-kernel test vectors\n",
    "We split train and test set\n",
    "\"\"\"\n",
    "dataset = ConfsDataset()                     \n",
    "total_len = len(dataset)                    \n",
    "train_len = int(var.TRAIN_PROP * total_len) \n",
    "test_len  = total_len - train_len   \n",
    "torch.manual_seed(42)                       # <-- any integer you like\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    dataset,\n",
    "    [train_len,  test_len]          # lengths in the same order\n",
    ")\n",
    "\n",
    "workers    = 2\n",
    "# Batch size\n",
    "batch_size = 100\n",
    "\n",
    "#train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,          # we usually want shuffling *only* for training\n",
    "    num_workers=workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "#test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "device = var.DEVICE\n",
    "\n",
    "\"\"\"\n",
    "Custom weights initialization\n",
    "\"\"\"  \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02) #nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0) #nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5381d690-21f7-4a69-96f0-2af353407c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TvGenerator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(4, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): PReLU(num_parameters=128)\n",
       "    (3): Conv2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=64)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): PReLU(num_parameters=256)\n",
       "    (10): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): PReLU(num_parameters=64)\n",
       "    (13): Linear(in_features=64, out_features=81920, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Declare the model\n",
    "\"\"\"\n",
    "model = mod.TvGenerator(var.NGPU,batch_size).to(device)\n",
    "if (device.type == 'cuda') and (var.NGPU > 1):\n",
    "    model = nn.DataParallel(model, list(range(var.NGPU)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5752d7bb-0d96-4bc0-82e7-67bb24858ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us        1.568s       178.52%        1.568s        1.568s             1  \n",
      "                                        model_inference        20.70%     406.441ms       100.00%        1.964s        1.964s       0.000us         0.00%     878.536ms     878.536ms             1  \n",
      "                                        aten::linalg_qr         1.21%      23.776ms         5.00%      98.222ms     122.778us     510.295ms        58.09%     515.795ms     644.744us           800  \n",
      "                                 maxwell_zgemm_32x32_cn         0.00%       0.000us         0.00%       0.000us       0.000us     238.095ms        27.10%     238.095ms     297.619us           800  \n",
      "void geqr2_smem_domino_fast<double2, double, 8, 512>...         0.00%       0.000us         0.00%       0.000us       0.000us     174.043ms        19.81%     174.043ms     217.553us           800  \n",
      "                                              aten::mul         4.69%      92.182ms        11.60%     227.708ms      14.232us     114.571ms        13.04%     142.747ms       8.922us         16000  \n",
      "                                              aten::sum         5.34%     104.826ms         7.49%     147.184ms       9.199us     114.115ms        12.99%     114.115ms       7.132us         16000  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      83.606ms         9.52%      83.606ms      10.451us          8000  \n",
      "void at::native::reduce_kernel<64, 4, at::native::Re...         0.00%       0.000us         0.00%       0.000us       0.000us      72.156ms         8.21%      72.156ms       9.019us          8000  \n",
      "                                            aten::copy_         4.67%      91.640ms         9.86%     193.664ms       7.308us      70.251ms         8.00%      70.258ms       2.651us         26502  \n",
      "                                 maxwell_zgemm_32x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us      58.236ms         6.63%      58.236ms      36.398us          1600  \n",
      "void at::native::reduce_kernel<256, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      41.959ms         4.78%      41.959ms       5.245us          8000  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      33.255ms         3.79%      33.255ms       1.889us         17600  \n",
      "                                            aten::clone         0.60%      11.694ms         5.20%     102.195ms      11.483us       0.000us         0.00%      32.193ms       3.617us          8900  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      30.965ms         3.52%      30.965ms       3.871us          8000  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      28.170ms         3.21%      28.170ms       3.521us          8000  \n",
      "                                              aten::sub         0.49%       9.572ms         1.55%      30.390ms      15.195us      24.158ms         2.75%      24.158ms      12.079us          2000  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      24.158ms         2.75%      24.158ms      12.079us          2000  \n",
      "                               aten::linalg_vector_norm         0.80%      15.688ms         1.09%      21.460ms      10.725us      23.241ms         2.65%      23.241ms      11.615us          2001  \n",
      "                                      aten::linalg_norm         0.09%       1.699ms         1.18%      23.119ms      11.560us       0.000us         0.00%      22.901ms      11.450us          2000  \n",
      "void at::native::reduce_kernel<256, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      22.901ms         2.61%      22.901ms      11.450us          2000  \n",
      "void larft_T_32<double2, 256>(int, double2*, int, do...         0.00%       0.000us         0.00%       0.000us       0.000us      20.389ms         2.32%      20.389ms      25.487us           800  \n",
      "void larft_vtv_32<double2, 128>(long, long, double2 ...         0.00%       0.000us         0.00%       0.000us       0.000us      12.509ms         1.42%      12.509ms      15.636us           800  \n",
      "                                            aten::zeros         0.55%      10.757ms         3.68%      72.360ms       9.521us       0.000us         0.00%       9.142ms       1.203us          7600  \n",
      "                                            aten::zero_         0.51%      10.105ms         2.28%      44.840ms       5.900us       0.000us         0.00%       9.142ms       1.203us          7600  \n",
      "                                            aten::fill_         0.73%      14.336ms         1.77%      34.735ms       4.570us       9.142ms         1.04%       9.142ms       1.203us          7600  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       7.427ms         0.85%       7.427ms       1.238us          6000  \n",
      "                                               aten::to         0.00%      15.846us         0.38%       7.519ms       3.760ms       0.000us         0.00%       5.300ms       2.650ms             2  \n",
      "                                         aten::_to_copy         0.00%      17.205us         0.38%       7.504ms       3.752ms       0.000us         0.00%       5.300ms       2.650ms             2  \n",
      "                         Memcpy HtoD (Pinned -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       5.300ms         0.60%       5.300ms       2.650ms             2  \n",
      "                                              aten::add         0.46%       9.041ms         0.66%      13.018ms       6.509us       3.671ms         0.42%       3.671ms       1.835us          2000  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.669ms         0.42%       3.669ms       1.835us          1999  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       3.526ms         0.40%       3.526ms       3.918us           900  \n",
      "                            copy_info_kernel(int, int*)         0.00%       0.000us         0.00%       0.000us       0.000us       2.415ms         0.27%       2.415ms       1.006us          2400  \n",
      "                                          aten::reshape         0.12%       2.427ms         0.90%      17.620ms      10.971us       0.000us         0.00%       2.254ms       1.403us          1606  \n",
      "                                             aten::triu         0.12%       2.356ms         0.30%       5.986ms       7.482us       2.028ms         0.23%       2.028ms       2.535us           800  \n",
      "void at::native::triu_tril_kernel<c10::complex<doubl...         0.00%       0.000us         0.00%       0.000us       0.000us       2.028ms         0.23%       2.028ms       2.535us           800  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.714ms         0.20%       1.714ms       1.072us          1600  \n",
      "                                           aten::linear         0.00%      12.253us         0.03%     532.433us     177.478us       0.000us         0.00%       1.659ms     553.120us             3  \n",
      "                                            aten::addmm         0.01%     198.258us         0.02%     481.768us     160.589us       1.659ms         0.19%       1.659ms     553.120us             3  \n",
      "                                            aten::stack         0.00%      12.784us         0.00%      63.555us      31.777us       0.000us         0.00%       1.623ms     811.441us             2  \n",
      "                                              aten::cat         0.00%      29.895us         0.00%      50.024us      25.012us       1.623ms         0.18%       1.623ms     811.441us             2  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       1.623ms         0.18%       1.623ms     811.441us             2  \n",
      "void batch_eye_kernel<double2, 5, 3>(long, long, dou...         0.00%       0.000us         0.00%       0.000us       0.000us       1.509ms         0.17%       1.509ms       1.887us           800  \n",
      "void lacpy_kernel<double2, double2, 5, 3>(long, long...         0.00%       0.000us         0.00%       0.000us       0.000us       1.451ms         0.17%       1.451ms       1.814us           800  \n",
      "                                maxwell_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.439ms         0.16%       1.439ms       1.439ms             1  \n",
      "                                          aten::complex         0.00%      21.257us         0.00%      60.686us      30.343us     672.141us         0.08%       1.344ms     672.141us             2  \n",
      "                                              aten::div         0.00%      50.421us         0.01%     220.126us     110.063us       1.254ms         0.14%       1.254ms     626.781us             2  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.252ms         0.14%       1.252ms       1.252ms             1  \n",
      "void orgqr_step1_kernel<double2, 5, 3>(int, int, int...         0.00%       0.000us         0.00%       0.000us       0.000us       1.076ms         0.12%       1.076ms       1.345us           800  \n",
      "                                           aten::conv2d         0.00%       8.243us         0.02%     390.646us     195.323us       0.000us         0.00%     926.099us     463.049us             2  \n",
      "                                      aten::convolution         0.00%      43.746us         0.02%     382.403us     191.201us       0.000us         0.00%     926.099us     463.049us             2  \n",
      "                                     aten::_convolution         0.00%      27.771us         0.02%     338.657us     169.329us       0.000us         0.00%     926.099us     463.049us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     672.141us         0.08%     672.141us     672.141us             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     571.177us         0.07%     571.177us       0.714us           800  \n",
      "                                aten::cudnn_convolution         0.01%     153.305us         0.01%     244.099us     122.049us     557.900us         0.06%     557.900us     278.950us             2  \n",
      "                                       aten::batch_norm         0.00%       9.203us         0.02%     327.863us      81.966us       0.000us         0.00%     502.506us     125.626us             4  \n",
      "                           aten::_batch_norm_impl_index         0.00%      17.645us         0.02%     318.660us      79.665us       0.000us         0.00%     502.506us     125.626us             4  \n",
      "                                 aten::cudnn_batch_norm         0.01%     113.041us         0.01%     188.552us      94.276us     471.817us         0.05%     471.817us     235.908us             2  \n",
      "void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us     413.704us         0.05%     413.704us     413.704us             1  \n",
      "                                            aten::prelu         0.00%      12.081us         0.01%     140.275us      35.069us       0.000us         0.00%     381.256us      95.314us             4  \n",
      "                                    aten::_prelu_kernel         0.00%      48.062us         0.00%      86.582us      21.645us     381.256us         0.04%     381.256us      95.314us             4  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     381.256us         0.04%     381.256us      95.314us             4  \n",
      "                                             aten::add_         0.00%      74.789us         0.01%     112.413us      18.736us     377.767us         0.04%     377.767us      62.961us             6  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     368.199us         0.04%     368.199us     184.099us             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     339.975us         0.04%     339.975us     339.975us             1  \n",
      "       _5x_cudnn_maxwell_scudnn_128x64_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     317.446us         0.04%     317.446us     317.446us             1  \n",
      "    _5x_cudnn_maxwell_scudnn_128x64_relu_interior_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     234.245us         0.03%     234.245us     234.245us             1  \n",
      "                                 maxwell_sgemm_64x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     190.948us         0.02%     190.948us     190.948us             1  \n",
      "void cudnn::bn_fw_tr_1C11_singleread<float, 512, tru...         0.00%       0.000us         0.00%       0.000us       0.000us      58.113us         0.01%      58.113us      58.113us             1  \n",
      "                                aten::native_batch_norm         0.00%      58.797us         0.01%     108.185us      54.092us      30.689us         0.00%      30.689us      15.344us             2  \n",
      "                               cudaPointerGetAttributes         0.00%      54.281us         0.00%      65.131us       4.342us      19.137us         0.00%      19.137us       1.276us            15  \n",
      "                                          cudaHostAlloc         2.19%      43.013ms         2.19%      43.096ms       4.788ms      18.432us         0.00%      18.432us       2.048us             9  \n",
      "void at::native::batch_norm_collect_statistics_chann...         0.00%       0.000us         0.00%       0.000us       0.000us      16.737us         0.00%      16.737us       8.368us             2  \n",
      "void cublasLt::splitKreduce_kernel<32, 16, int, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      15.552us         0.00%      15.552us       7.776us             2  \n",
      "                                maxwell_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      14.272us         0.00%      14.272us      14.272us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.568us         0.00%       9.568us       2.392us             4  \n",
      "void at::native::batch_norm_transform_input_channels...         0.00%       0.000us         0.00%       0.000us       0.000us       9.152us         0.00%       9.152us       4.576us             2  \n",
      "void cask__5x_cudnn::computeOffsetsKernel<false, fal...         0.00%       0.000us         0.00%       0.000us       0.000us       6.209us         0.00%       6.209us       3.105us             2  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        18.51%     363.492ms        18.51%     363.503ms     363.503ms       0.000us         0.00%       5.920us       5.920us             1  \n",
      "void at::native::(anonymous namespace)::unrolled_ele...         0.00%       0.000us         0.00%       0.000us       0.000us       4.800us         0.00%       4.800us       2.400us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.760us         0.00%       1.760us       1.760us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.376us         0.00%       1.376us       1.376us             1  \n",
      "                                            aten::empty         1.04%      20.383ms         1.06%      20.822ms       2.258us       0.000us         0.00%       0.000us       0.000us          9220  \n",
      "                                          aten::random_         0.00%      38.379us         0.00%      38.379us      19.190us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                             aten::item         0.00%       7.519us         0.00%      12.432us       6.216us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                              aten::_local_scalar_dense         0.00%       4.913us         0.00%       4.913us       2.457us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                         aten::randperm         0.00%      27.562us         0.00%      69.020us      34.510us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                    aten::scalar_tensor         0.00%       7.165us         0.00%       7.165us       7.165us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                          aten::resize_         0.00%       5.907us         0.00%       5.907us       1.969us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                     aten::resolve_conj         0.00%       0.550us         0.00%       0.550us       0.550us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                      aten::resolve_neg         0.00%       0.568us         0.00%       0.568us       0.568us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                    aten::empty_strided         1.02%      19.947ms         1.12%      21.903ms       2.701us       0.000us         0.00%       0.000us       0.000us          8108  \n",
      "                                        cudaMemcpyAsync         0.97%      18.961ms         0.97%      18.961ms      21.021us       0.000us         0.00%       0.000us       0.000us           902  \n",
      "                                  cudaStreamSynchronize         0.27%       5.298ms         0.27%       5.302ms       2.651ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                        cudaEventRecord         0.00%      12.818us         0.00%      12.818us       2.136us       0.000us         0.00%       0.000us       0.000us             6  \n",
      "                                  cudaStreamIsCapturing         0.00%      65.324us         0.00%      65.324us       0.933us       0.000us         0.00%       0.000us       0.000us            70  \n",
      "                                  cudaStreamGetPriority         0.00%       2.451us         0.00%       2.451us       0.409us       0.000us         0.00%       0.000us       0.000us             6  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.00%       1.793us         0.00%       1.793us       0.299us       0.000us         0.00%       0.000us       0.000us             6  \n",
      "                                       cudaLaunchKernel        11.62%     228.135ms        11.62%     228.141ms       2.795us       0.000us         0.00%       0.000us       0.000us         81633  \n",
      "                                    cudaPeekAtLastError         0.00%       1.482us         0.00%       1.482us       0.370us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                        cudaMemsetAsync         0.09%       1.768ms         0.09%       1.768ms       2.205us       0.000us         0.00%       0.000us       0.000us           802  \n",
      "                                             aten::view         0.04%     774.671us         0.04%     774.671us       0.951us       0.000us         0.00%       0.000us       0.000us           815  \n",
      "                                       aten::empty_like         0.53%      10.493ms         1.65%      32.457ms       3.685us       0.000us         0.00%       0.000us       0.000us          8808  \n",
      "                                   cudaFuncSetAttribute         0.00%       7.140us         0.00%       7.140us       7.140us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                          aten::flatten         0.00%       3.190us         0.00%       5.659us       5.659us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                                aten::t         0.00%      20.434us         0.00%      38.412us      12.804us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                        aten::transpose         0.00%       7.624us         0.00%      17.978us       5.993us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                       aten::as_strided         3.10%      60.959ms         3.10%      60.959ms       0.254us       0.000us         0.00%       0.000us       0.000us        239718  \n",
      "                                             cudaMalloc         0.49%       9.715ms         0.49%       9.715ms     126.168us       0.000us         0.00%       0.000us       0.000us            77  \n",
      "                                            aten::slice        13.00%     255.363ms        15.05%     295.608ms       1.811us       0.000us         0.00%       0.000us       0.000us        163210  \n",
      "                                           aten::select         3.70%      72.623ms         4.25%      83.559ms       2.043us       0.000us         0.00%       0.000us       0.000us         40904  \n",
      "                                     aten::_unsafe_view         0.03%     502.453us         0.03%     502.453us       0.628us       0.000us         0.00%       0.000us       0.000us           800  \n",
      "                                          aten::numpy_T         0.07%       1.366ms         0.19%       3.817ms       2.386us       0.000us         0.00%       0.000us       0.000us          1600  \n",
      "                                          aten::permute         0.10%       2.034ms         0.12%       2.451ms       1.532us       0.000us         0.00%       0.000us       0.000us          1600  \n",
      "                                        aten::new_empty         0.04%     738.614us         0.12%       2.326ms       2.908us       0.000us         0.00%       0.000us       0.000us           800  \n",
      "                                     cudaGetDeviceCount         0.00%       0.335us         0.00%       0.335us       0.335us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                             cudaGetDeviceProperties_v2         0.01%     114.414us         0.01%     114.414us     114.414us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                 cudaDeviceGetAttribute         0.00%       1.486us         0.00%       1.486us       0.149us       0.000us         0.00%       0.000us       0.000us            10  \n",
      "                                               cudaFree         0.00%       4.053us         0.00%       4.053us       0.811us       0.000us         0.00%       0.000us       0.000us             5  \n",
      "                              cudaStreamCreateWithFlags         0.04%     773.237us         0.04%     773.237us     257.746us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                            aten::_conj         0.59%      11.503ms         0.75%      14.814ms       1.852us       0.000us         0.00%       0.000us       0.000us          8000  \n",
      "                                            aten::alias         0.17%       3.311ms         0.17%       3.311ms       0.414us       0.000us         0.00%       0.000us       0.000us          8000  \n",
      "                                        aten::unsqueeze         1.26%      24.815ms         1.47%      28.884ms       1.805us       0.000us         0.00%       0.000us       0.000us         16000  \n",
      "                                  cudaDeviceSynchronize         0.00%      16.241us         0.00%      16.241us      16.241us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.964s\n",
      "Self CUDA time total: 878.499ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activities = [ProfilerActivity.CPU,ProfilerActivity.CUDA]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"\"\n",
    "sort_by_keyword = device + \"_time_total\"\n",
    "criterion = lf.CustomLossTorch().to(device)  \n",
    "with profile(activities=activities, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        for gconfs, near_kernel, ID in train_loader:\n",
    "            gconfs, near_kernel = gconfs.to(device), near_kernel.to(device)\n",
    "            \n",
    "            pred = model(gconfs).view(batch_size, var.NV, 4, var.NT, var.NX) \n",
    "            real = torch.stack([pred[:,:, 0], pred[:,:, 1]], dim=2)   # (B,NV,2,NT,NX)\n",
    "            imag = torch.stack([pred[:,:, 2], pred[:,:, 3]], dim=2)   # (B,NV,2,NT,NX)\n",
    "            pred_complex = torch.complex(real, imag)                  # (B,NV,2,NT,NX)\n",
    "\n",
    "            #Normalizing the fake test vectors\n",
    "            norms = torch.linalg.vector_norm(pred_complex[:,:],dim=(-3,-2, -1)).view(batch_size, var.NV, 1, 1, 1)\n",
    "            norms_broadcastable = norms.view(batch_size, var.NV, 1, 1, 1)\n",
    "            pred_complex_normalized = pred_complex / norms_broadcastable\n",
    "       \n",
    "            #We assemble P, P^+ with the SAP test vectors and find other vectors that are similar to them.\n",
    "            loss = criterion(near_kernel, pred_complex_normalized)   # loss is a scalar Tensor\n",
    "            break\n",
    "print(prof.key_averages().table(sort_by=sort_by_keyword, row_limit=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5858c43-abe0-4be0-8d61-3f1cf3c9346b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert.py\n",
    "#from glob import glob\n",
    "#from opendataset import read_binary_conf\n",
    "\n",
    "PATH = '/wsgjsc/home/nietocastellanos1/Documents/SchwingerModel/fermions/SchwingerModel' + \\\n",
    "        '/confs/b{0}_{1}x{2}/{3}'.format(int(var.BETA),var.NX,var.NT,var.M0_FOLDER)\n",
    "\n",
    "#PATH='sap/near_kernel/b{0}_{1}x{2}/{3}'.format(int(var.BETA),var.NX,var.NT,var.M0_FOLDER)\n",
    "\n",
    "conf_files = []\n",
    "for path in sorted(glob(PATH+\"/*.ctxt\")):\n",
    "    conf_files.append(path)\n",
    "    #arr = read_binary_conf(\"\",path)\n",
    "    #torch.save(torch.from_numpy(arr), path.replace(\".tv\", \".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4d279-9850-43e5-ac33-4b7ece69dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "conf_file = conf_files[idx]\n",
    "gauge_conf = read_binary_conf(None,conf_file)\n",
    "#tvectors = torch.zeros(var.NV,2,var.NT,var.NX,dtype=torch.complex128)\n",
    "\n",
    "#gauge_conf = torch.load(self.conf_files[idx].replace('.ctxt','.pt'), mmap=True)\n",
    "#tvectors = torch.load(self.tv_files[idx].replace('.tv','.pt'), mmap=True)\n",
    "        \n",
    "real = torch.tensor(np.real(gauge_conf), dtype=torch.float32)\n",
    "imag = torch.tensor(np.imag(gauge_conf), dtype=torch.float32)\n",
    "gauge_conf = torch.tensor(np.array([real,imag])).reshape(4, var.NT, var.NX)  \n",
    "        \n",
    "#for tvID in range(var.NV):\n",
    "#    vector = read_binary_conf(None,tv_files[idx][tvID])\n",
    "#    real = torch.tensor(np.real(vector), dtype=torch.float64)\n",
    "#    imag = torch.tensor(np.imag(vector), dtype=torch.float64)\n",
    "#    tvectors[tvID] = torch.complex(real,imag).reshape(2, var.NT, var.NX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d25cd-507a-4332-99ef-2a3280bb36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_conf_2 = torch.load(conf_file.replace('.ctxt','.pt'), mmap=True,weights_only=True)\n",
    "gauge_conf_2 = torch.cat([torch.real(gauge_conf_2), torch.imag(gauge_conf_2)], dim=0).float()   # [4, NT, NX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79423e75-1359-4d91-9991-081f9f7499f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_conf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72595f05-c757-4c34-a36d-9177f381abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gauge_conf[0,0,0],gauge_conf[2,0,0])\n",
    "print(gauge_conf[1,0,0],gauge_conf[3,0,0])\n",
    "\n",
    "print(gauge_conf_2[0,0,0],gauge_conf_2[2,0,0])\n",
    "print(gauge_conf_2[1,0,0],gauge_conf_2[3,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880bd24-f5fb-4604-bbe7-2e2a57c9b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvectors = torch.load(\"sap/near_kernel/b2_32x32/m-018/tvector_32x32_b20000_m-01884_nconf264_tv12.tv\".replace('.tv','.pt'), mmap=True,weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddc25d-4bf0-422e-8b03-904971a15045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
