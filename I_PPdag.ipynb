{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed9cfe-e927-4990-85af-f03d5a626030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.parallel\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import parameters as var #Configuration and coarsening parameters\n",
    "var.init() #initializes parameters\n",
    "import utils as ut #Some utility functions \n",
    "import loss_function as lf #Custom loss function\n",
    "\n",
    "import operators_torch as op #Interpolator and prolongator given a set of test vectors\n",
    "from opendataset import ConfsDataset #class for opening gauge confs\n",
    "import model as mod #import machine learning model\n",
    "from train import train, evaluate\n",
    "\n",
    "#--------Most likely I will need some of these in the future-------#\n",
    "#import torch.optim as optim\n",
    "#import torchvision.transforms as transforms\n",
    "#import torchvision.utils as vutils\n",
    "var.print_parameters()\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if var.NGPU>0\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc55b9-a808-4bd1-939b-7b97b0b1d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the configurations and the near-kernel test vectors\n",
    "We split train and test set\n",
    "\"\"\"\n",
    "dataset = ConfsDataset()                     \n",
    "total_len = len(dataset)                    \n",
    "train_len = int(var.TRAIN_PROP * total_len) \n",
    "test_len  = total_len - train_len   \n",
    "torch.manual_seed(42)                       # <-- any integer you like\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    dataset,\n",
    "    [train_len,  test_len]          # lengths in the same order\n",
    ")\n",
    "\n",
    "workers    = 8\n",
    "# Batch size\n",
    "batch_size = 50\n",
    "\n",
    "#train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,          # we usually want shuffling *only* for training\n",
    "    num_workers=workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "#test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "#----returns a tensor of size [ [batch_size,4,Nt,Nx], [batch_size,Nv,2,Nt,Nx], [batch_size]]----#\n",
    "#    The first entry is real and second one complex. The last entry has the indices of the confs.\n",
    "#first_batch = next(iter(train_loader)) \n",
    "#--------------------------------------\n",
    "\n",
    "device = var.DEVICE\n",
    "#first_batch[0][0].shape\n",
    "#print(\"Re(U0)\",first_batch[0][0][0,0,0])\n",
    "#print(\"Re(U1)\",first_batch[0][0][1,0,0])\n",
    "#print(\"Im(U0)\",first_batch[0][0][2,0,0])\n",
    "#print(\"Im(U1)\",first_batch[0][0][3,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f289a1-59df-452d-afea-03d022c06cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom weights initialization\n",
    "\"\"\"  \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 1.0) #nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 1.0)\n",
    "        nn.init.constant_(m.bias.data, 0.0) #nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755b569-b7b0-4f46-a44c-31800805debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declare the model\n",
    "\"\"\"\n",
    "model = mod.TvGenerator(var.NGPU,batch_size).to(device)\n",
    "if (device.type == 'cuda') and (var.NGPU > 1):\n",
    "    model = nn.DataParallel(model, list(range(var.NGPU)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "model.apply(weights_init)\n",
    "print(\"\")\n",
    "# Print the model\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15be69-012a-4eb9-aed1-b8786f742f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate for optimizers\n",
    "lr = 0.1\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.9\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999),weight_decay=0)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a6b03-d65f-4e60-958e-200526d45c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "version = 1\n",
    "epochs = 5\n",
    "losses = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, optimizer,losses,version)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478410b5-817c-4c2c-845b-16d22a100f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(np.arange(len(losses)),losses)\n",
    "plt.title(\"Batch size = {0}, No. of examples = {1}\".format(batch_size,train_len))\n",
    "plt.ylabel(\"Loss (training)\")\n",
    "plt.xlabel(\"Epoch per batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95e8d4-c64c-43f9-8885-ba1553be9b2e",
   "metadata": {},
   "source": [
    "# Check loss on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8c1af-b877-4c8b-bb5d-0f43eede751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, dtest_loss, test_batch_losses = evaluate(test_loader, model, device,version)\n",
    "print(f'Test average loss: {test_loss:.6f} +- {dtest_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb6cb0-0406-4497-ad7a-4f5cae67b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(dpi=150)\n",
    "#plt.plot(np.arange(len(test_batch_losses)),test_batch_losses,linestyle='',marker='o',markersize=10)\n",
    "#plt.title(\"Batch size = {0}, No. of examples = {1}\".format(batch_size,test_len))\n",
    "#plt.ylabel(\"Loss (test)\")\n",
    "#plt.xlabel(\"ID\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42df56-fd90-4c00-8888-2ed6120a70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.SavePredictions(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029ccb4-1507-4ba3-a149-34e0e719e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader)) \n",
    "    confs_batch = batch[0].to(device)          # (B, …)\n",
    "    pred = model(confs_batch)                  # (B, 4*NV, NT, NX)\n",
    "    confsID = batch[2]\n",
    "    B = pred.shape[0]\n",
    "    pred = pred.view(B, var.NV, 4, var.NT, var.NX)   # (B,NV,4,NT,NX)\n",
    "    # Build complex tensor (B,NV,2,NT,NX)\n",
    "    real = torch.stack([pred[:, :, 0], pred[:, :, 1]], dim=2)   # (B,NV,2,NT,NX)\n",
    "    imag = torch.stack([pred[:, :, 2], pred[:, :, 3]], dim=2)   # (B,NV,2,NT,NX)\n",
    "    pred_complex = torch.complex(real, imag)\n",
    "    norms = torch.linalg.vector_norm(pred_complex[:,:],dim=(-3,-2, -1)).view(batch_size, var.NV, 1, 1, 1)\n",
    "    pred_complex_normalized = pred_complex / norms\n",
    "    pred_complex_normalized = pred_complex_normalized.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9280721-7950-435b-a4a8-8ab01e9fad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = 0\n",
    "conf = 5 #ConfID in the test_loader\n",
    "factor = 1\n",
    "norm = np.linalg.norm(batch[1][conf][tv].reshape(2*var.NX*var.NT))\n",
    "norm_pred = np.linalg.norm(pred_complex_normalized[conf,tv].reshape(2*var.NX*var.NT))\n",
    "print(\"Norm\",norm,norm_pred)\n",
    "plt.title(\"Components distribution for conf {0} and test vector {1}\".format(conf,tv))\n",
    "\n",
    "plt.scatter(np.real(batch[1][conf][tv].reshape(2*var.NX*var.NT))/norm,\n",
    "            np.imag(batch[1][conf][tv].reshape(2*var.NX*var.NT))/norm,\n",
    "            marker=\"*\",label=\"SAP tv\")\n",
    "\n",
    "plt.scatter(np.real(pred_complex_normalized[conf,tv].reshape(2*var.NX*var.NT))/norm_pred,\n",
    "            np.imag(factor*pred_complex_normalized[conf,tv].reshape(2*var.NX*var.NT))/norm_pred,\n",
    "            label=\"Fake tv\")\n",
    "\n",
    "plt.xlabel(\"Re\")\n",
    "plt.ylabel(\"Im\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a3d04-04ea-4b54-88d2-aeb5b0ed5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch = next(iter(train_loader)) \n",
    "    confs_batch = batch[0].to(device)          # (B, …)\n",
    "    pred = model(confs_batch)                  # (B, 4*NV, NT, NX)\n",
    "    confsID = batch[2]\n",
    "    B = pred.shape[0]\n",
    "    pred = pred.view(B, var.NV, 4, var.NT, var.NX)   # (B,NV,4,NT,NX)\n",
    "    # Build complex tensor (B,NV,2,NT,NX)\n",
    "    real = torch.stack([pred[:, :, 0], pred[:, :, 1]], dim=2)   # (B,NV,2,NT,NX)\n",
    "    imag = torch.stack([pred[:, :, 2], pred[:, :, 3]], dim=2)   # (B,NV,2,NT,NX)\n",
    "    pred_complex = torch.complex(real, imag)\n",
    "    norms = torch.linalg.vector_norm(pred_complex[:,:],dim=(-3,-2, -1)).view(batch_size, var.NV, 1, 1, 1)\n",
    "    pred_complex_normalized = pred_complex / norms\n",
    "    pred_complex_normalized = pred_complex_normalized.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a506df-7d71-44ab-a8a6-88376b9f653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = 10\n",
    "conf = 1 #ConfID in the test_loader\n",
    "\n",
    "norm = np.linalg.norm(batch[1][conf][tv].reshape(2*var.NX*var.NT))\n",
    "norm_pred = np.linalg.norm(pred_complex_normalized[conf,tv].reshape(2*var.NX*var.NT))\n",
    "print(\"Norm\",norm,norm_pred)\n",
    "\n",
    "plt.title(\"Components distribution for conf {0} and test vector {1}\".format(conf,tv))\n",
    "\n",
    "plt.scatter(np.real(batch[1][conf][tv].reshape(2*var.NX*var.NT))/norm,\n",
    "            np.imag(batch[1][conf][tv].reshape(2*var.NX*var.NT))/norm,\n",
    "            marker=\"*\",\n",
    "            label=\"SAP tv\")\n",
    "\n",
    "plt.scatter(np.real(pred_complex_normalized[conf,tv].reshape(2*var.NX*var.NT))/norm_pred,\n",
    "            np.imag(pred_complex_normalized[conf,tv].reshape(2*var.NX*var.NT))/norm_pred,\n",
    "            label=\"Fake tv\")\n",
    "plt.xlabel(\"Re\")\n",
    "plt.ylabel(\"Im\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c645696-481f-482a-a68c-6302b1b0a003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
