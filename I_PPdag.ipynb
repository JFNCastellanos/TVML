{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ed9cfe-e927-4990-85af-f03d5a626030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Configuration parameters ***********\n",
      "* β=2, Nx=32, Nt=32\n",
      "* Lattice sites=2048\n",
      "* m0=-0.1884\n",
      "* blocks_x=2, blocks_t=2 (for the aggregation)\n",
      "* Nv=14\n",
      "* Number of confs=1000\n",
      "* Confs used for training=900\n",
      "************************************************\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.parallel\n",
    "import random\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import parameters as var #Configuration and coarsening parameters\n",
    "var.init() #initializes parameters\n",
    "import utils as ut #Some utility functions \n",
    "import loss_function as lf #Custom loss function\n",
    "\n",
    "import operators_torch as op #Interpolator and prolongator given a set of test vectors\n",
    "from opendataset import ConfsDataset #class for opening gauge confs\n",
    "import model as mod #import machine learning model\n",
    "\n",
    "#--------Most likely I will need some of these in the future-------#\n",
    "#import matplotlib.pyplot as plt\n",
    "#import torch.optim as optim\n",
    "#import torch.utils.data\n",
    "#import torchvision.datasets as dset\n",
    "#import torchvision.transforms as transforms\n",
    "#import torchvision.utils as vutils\n",
    "var.print_parameters()\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if var.NGPU>0\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc55b9-a808-4bd1-939b-7b97b0b1d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the configurations and the near-kernel test vectors\n",
    "We split train and test set\n",
    "\"\"\"\n",
    "dataset = ConfsDataset()                     \n",
    "total_len = len(dataset)                    \n",
    "train_len = int(var.TRAIN_PROP * total_len) \n",
    "test_len  = total_len - train_len   \n",
    "torch.manual_seed(42)                       # <-- any integer you like\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    dataset,\n",
    "    [train_len,  test_len]          # lengths in the same order\n",
    ")\n",
    "\n",
    "workers    = 2\n",
    "# Batch size\n",
    "batch_size = 100\n",
    "\n",
    "#train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,          # we usually want shuffling *only* for training\n",
    "    num_workers=workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "#test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "#----returns a tensor of size [ [batch_size,4,Nx,Nt], [batch_size,Nv,2,Nx,Nt], [batch_size]]----#\n",
    "#    The first entry is real and second one complex. The last entry has the indices of the confs.\n",
    "#first_batch = next(iter(train_loader)) \n",
    "#--------------------------------------\n",
    "\n",
    "device = var.DEVICE\n",
    "#first_batch[0][0].shape\n",
    "#print(\"Re(U0)\",first_batch[0][0][0,0,0])\n",
    "#print(\"Re(U1)\",first_batch[0][0][1,0,0])\n",
    "#print(\"Im(U0)\",first_batch[0][0][2,0,0])\n",
    "#print(\"Im(U1)\",first_batch[0][0][3,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f289a1-59df-452d-afea-03d022c06cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom weights initialization\n",
    "\"\"\"  \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02) #nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0) #nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755b569-b7b0-4f46-a44c-31800805debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declare the model\n",
    "\"\"\"\n",
    "model = mod.TvGenerator(var.NGPU).to(device)\n",
    "if (device.type == 'cuda') and (var.NGPU > 1):\n",
    "    model = nn.DataParallel(model, list(range(var.NGPU)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "model.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15be69-012a-4eb9-aed1-b8786f742f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate for optimizers\n",
    "lr = 0.001\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.9\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a34b31-1a62-485d-acdd-b9a04563c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "def train(dataloader, model, optimizer):\n",
    "    \"\"\"\n",
    "    Trains the model based on the test loader\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : torch.utils.data.DataLoader\n",
    "        DataLoader that yields the training loader:\n",
    "        (confs_batch, near_kernel)\n",
    "    model : torch.nn.Module\n",
    "        The model to evaluate.\n",
    "    Appends loss to losses (list declared outside the function)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    criterion = lf.CustomLossTorch().to(device)               # instantiate once, reuse\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        # -------------------------------------------------\n",
    "        # Load the data\n",
    "        # -------------------------------------------------\n",
    "        confs_batch   = batch[0].to(device)            # shape (B, …)\n",
    "        near_kernel   = batch[1].to(device)            # shape (B, NV, 2, NT, NX)\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Forward pass of the model → predicted test vectors\n",
    "        # -------------------------------------------------\n",
    "        # model returns a real‑valued tensor of shape [B, 4*NV, NT, NX]\n",
    "        pred = model(confs_batch)                     # still a torch Tensor\n",
    "        # -------------------------------------------------\n",
    "        # Reshape / convert to complex dtype\n",
    "        # -------------------------------------------------\n",
    "        # Example: real/imag in 4 channels (Re0, Re1, Im0, Im1)\n",
    "        B = pred.shape[0]\n",
    "        pred = pred.view(B, var.NV, 4, var.NT, var.NX)      # (B,NV,4,NT,NX)\n",
    "\n",
    "        # Build a complex tensor of shape (B, NV, 2, NT, NX)\n",
    "        #   channel 0 → real part of component 0\n",
    "        #   channel 1 → real part of component 1\n",
    "        #   channel 2 → imag part of component 0\n",
    "        #   channel 3 → imag part of component 1\n",
    "        real = torch.stack([pred[:,:, 0], pred[:,:, 1]], dim=2)   # (B,NV,2,NT,NX)\n",
    "        imag = torch.stack([pred[:,:, 2], pred[:,:, 3]], dim=2)   # (B,NV,2,NT,NX)\n",
    "        pred_complex = torch.complex(real, imag)                  # (B,NV,2,NT,NX)\n",
    "        # -------------------------------------------------\n",
    "        # Compute loss (still on the same device)\n",
    "        # -------------------------------------------------\n",
    "        #We assemble P, P^+ with the SAP test vectors and find other vectors that are similar to them.\n",
    "        loss = criterion(near_kernel, pred_complex)   # loss is a scalar Tensor\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Back‑propagation\n",
    "        # -------------------------------------------------\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Logging\n",
    "        # -------------------------------------------------\n",
    "        loss_val = loss.item()\n",
    "        current = (batch_id + 1) * B\n",
    "        losses.append(loss_val)\n",
    "        print(f\"loss: {loss_val:>7f}  [{current:>5d}/{train_len:>5d}]\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a6b03-d65f-4e60-958e-200526d45c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478410b5-817c-4c2c-845b-16d22a100f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(np.arange(epochs*(train_len//batch_size)),losses)\n",
    "plt.title(\"Batch size = {0}, No. of examples = {1}\".format(batch_size,train_len))\n",
    "plt.ylabel(\"Loss (training)\")\n",
    "plt.xlabel(\"Epoch per batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95e8d4-c64c-43f9-8885-ba1553be9b2e",
   "metadata": {},
   "source": [
    "# Check loss on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06f8da-307a-4528-ba90-574757988ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, device, criterion=None):\n",
    "    \"\"\"\n",
    "    Run a forward pass on the whole test set and return\n",
    "    the mean loss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataloader : torch.utils.data.DataLoader\n",
    "        DataLoader that yields the same tuple format as the training loader:\n",
    "        (confs_batch, near_kernel)\n",
    "    model : torch.nn.Module\n",
    "        The model to evaluate. It will be switched to ``eval`` mode for the\n",
    "        duration of the call and restored to its previous mode afterwards.\n",
    "    device : torch.device\n",
    "        Where the tensors should live (e.g. ``torch.device('cuda')``).\n",
    "    criterion : torch.nn.Module, optional\n",
    "        A loss object that implements ``__call__(target, prediction)``.\n",
    "        If ``None`` a fresh ``lf.CustomLossTorch`` instance will be created\n",
    "        on the supplied ``device`` (the same as in the training loop).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    avg_loss : float\n",
    "        Mean loss over all batches (scalar).\n",
    "    batch_losses : list[float]\n",
    "        Individual batch losses.\n",
    "    \"\"\"\n",
    "    # ------------------------------------------------------------------\n",
    "    # Put the model in eval mode – turns off dropout, batch‑norm updates\n",
    "    # ----------------------------------------------------------------\n",
    "    was_training = model.training          # remember the original state\n",
    "    model.eval()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Build (or reuse) the loss object on the proper device\n",
    "    # ------------------------------------------------------------------\n",
    "    if criterion is None:\n",
    "        criterion = lf.CustomLossTorch().to(device)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Containers for the per‑batch losses\n",
    "    # ------------------------------------------------------------------\n",
    "    batch_losses = []\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # No gradient tracking – saves memory and speeds up the forward pass\n",
    "    # ------------------------------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch in enumerate(dataloader):\n",
    "            # -------------------------------------------------\n",
    "            # Load the data (move to the same device as the model)\n",
    "            # -------------------------------------------------\n",
    "            confs_batch = batch[0].to(device)          # (B, …)\n",
    "            near_kernel = batch[1].to(device)          # (B, NV, 2, NT, NX)\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # Forward pass – exactly the same reshaping as in training\n",
    "            # -------------------------------------------------\n",
    "            pred = model(confs_batch)                  # (B, 4*NV, NT, NX)\n",
    "\n",
    "            B = pred.shape[0]\n",
    "            pred = pred.view(B, var.NV, 4, var.NT, var.NX)   # (B,NV,4,NT,NX)\n",
    "\n",
    "            # Build complex tensor (B,NV,2,NT,NX)\n",
    "            real = torch.stack([pred[:, :, 0], pred[:, :, 1]], dim=2)   # (B,NV,2,NT,NX)\n",
    "            imag = torch.stack([pred[:, :, 2], pred[:, :, 3]], dim=2)   # (B,NV,2,NT,NX)\n",
    "            pred_complex = torch.complex(real, imag)\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # Compute loss (still on the same device)\n",
    "            # -------------------------------------------------\n",
    "            loss = criterion(near_kernel, pred_complex)   # scalar Tensor\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # Store loss value (as a Python float)\n",
    "            # -------------------------------------------------\n",
    "            loss_val = loss.item()\n",
    "            batch_losses.append(loss_val)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Compute the mean loss over the whole set\n",
    "    # ------------------------------------------------------------------\n",
    "    batch_losses = np.array(batch_losses)\n",
    "    avg_loss = np.mean(batch_losses) \n",
    "    std_err = np.std(batch_losses)/np.sqrt(len(batch_losses))\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Restore the original training/eval state of the model\n",
    "    # ------------------------------------------------------------------\n",
    "    model.train(was_training)\n",
    "\n",
    "    return avg_loss, std_err, batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8c1af-b877-4c8b-bb5d-0f43eede751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, dtest_loss, test_batch_losses = evaluate(test_loader, model, device)\n",
    "print(f'Test average loss: {test_loss:.6f} +- {dtest_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb6cb0-0406-4497-ad7a-4f5cae67b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(np.arange(len(test_batch_losses)),test_batch_losses,linestyle='',marker='o',markersize=10)\n",
    "plt.title(\"Batch size = {0}, No. of examples = {1}\".format(batch_size,test_len))\n",
    "plt.ylabel(\"Loss (test)\")\n",
    "plt.xlabel(\"ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fdb6c-bc60-46f4-a774-6b174ee475b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SavePredictions(dataloader, model, device):\n",
    "    \"\"\"\n",
    "    Saves test vectors predicted with the model into binary files.\n",
    "    One file per test vector. The data layout is the same as for\n",
    "    the near-kernel vectors used for the training.\n",
    "    x, t, μ, Re(Uμ), Im(Uμ)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch in enumerate(dataloader):\n",
    "            confs_batch = batch[0].to(device)          # (B, …)\n",
    "            pred = model(confs_batch)                  # (B, 4*NV, NT, NX)\n",
    "            confsID = batch[2]\n",
    "\n",
    "            B = pred.shape[0]\n",
    "            pred = pred.view(B, var.NV, 4, var.NT, var.NX)   # (B,NV,4,NT,NX)\n",
    "\n",
    "            # Build complex tensor (B,NV,2,NT,NX)\n",
    "            real = torch.stack([pred[:, :, 0], pred[:, :, 1]], dim=2)   # (B,NV,2,NT,NX)\n",
    "            imag = torch.stack([pred[:, :, 2], pred[:, :, 3]], dim=2)   # (B,NV,2,NT,NX)\n",
    "            pred_complex = torch.complex(real, imag).detach().cpu().numpy()\n",
    "            for i in range(len(confs_batch)):\n",
    "                for tv in range(var.NV):\n",
    "                    file_path = \"fake_tv/b{0}_{1}x{2}/{3}/conf{4}_fake_tv{5}.tv\".format(var.BETA,var.NX,var.NT,var.M0_FOLDER,confsID[i],tv)\n",
    "                    fmt = \"<3i2d\"\n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        for x in range(var.NX):\n",
    "                            for t in range(var.NT):\n",
    "                                for mu in range(2):\n",
    "                                    value = pred_complex[i,tv,mu,t,x]\n",
    "                                    Re = np.real(value)\n",
    "                                    Im = np.imag(value)\n",
    "                                    data = struct.pack(fmt, int(x), int(t), int(mu), float(Re), float(Im))\n",
    "                                    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42df56-fd90-4c00-8888-2ed6120a70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SavePredictions(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fe2f8-53a8-48ca-9554-90b03ce04573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029ccb4-1507-4ba3-a149-34e0e719e77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
